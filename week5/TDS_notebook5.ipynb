{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week5 Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## large language models (LLMs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module covers the practical usage of large language models (LLMs) -- a relatively a new area.\n",
    "\n",
    "This module is experimental. Things may break when trying these notebooks or during your GA. Try again, gently.\n",
    "\n",
    "**LLMs incur a cost**. We have created API keys for everyone to use gpt-3.5-turbo and text-embedding-small. Your usage is limited to **50 cents** for this course. Don't exceed that.\n",
    "\n",
    "Use [AI Proxy](https://github.com/sanand0/aiproxy) instead of OpenAI. Specifically:\n",
    "\n",
    "1. Replace your API to `https://api.openai.com/...` with `https://aiproxy.sanand.workers.dev/openai/...`\n",
    "2. Replace the **OPENAI_API_KEY** with the **AIPROXY_TOKEN** that someone will give you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM Sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll learn how to use large language models (LLMs) for sentiment analysis and classification, covering:\n",
    "\n",
    "- **Sentiment Analysis:** Use OpenAI API to identify the sentiment of movie reviews as positive or negative.\n",
    "- **Prompt Engineering:** Learn how to craft effective prompts to get desired results from LLMs.\n",
    "- **LLM Training:** Understand how to train LLMs by providing examples and feedback.\n",
    "- **OpenAI API Integration:** Integrate OpenAI API into Python code to perform sentiment analysis.\n",
    "- **Tokenization:** Learn about tokenization and its impact on LLM input and cost.\n",
    "- **Zero-Shot, One-Shot, and Multi-Shot Learning:** Understand different approaches to using LLMs for learning.\n",
    "\n",
    "Here are the links used in the video:\n",
    "\n",
    "- [Jupyter Notebook](./TDS_LLM_Sentiment_Analysis.ipynb)\n",
    "- [Movie reviews dataset](./week5_downloads/movie-reviews.csv)\n",
    "- [OpenAI Playground](https://platform.openai.com/playground/chat)\n",
    "- [OpenAI Pricing](https://openai.com/api/pricing/)\n",
    "- [OpenAI Tokenizer](https://platform.openai.com/tokenizer)\n",
    "- [OpenAI API Reference](https://platform.openai.com/docs/api-reference/introduction)\n",
    "- [OpenAI Docs](https://platform.openai.com/docs/overview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll learn how to use LLMs to extract structure from unstructured data, covering:\n",
    "\n",
    "- **LLM for Data Extraction:** Use OpenAI's API to extract structured information from unstructured data like addresses.\n",
    "- **JSON Schema:** Define a JSON schema to ensure consistent and structured output from the LLM.\n",
    "- **Prompt Engineering:** Craft effective prompts to guide the LLM's response and improve accuracy.\n",
    "- **Data Cleaning:** Use string functions and OpenAI's API to clean and standardize data.\n",
    "- **Data Analysis:** Analyze extracted data using Pandas to gain insights.\n",
    "- **LLM Limitations:** Understand the limitations of LLMs, including potential errors and inconsistencies in output.\n",
    "- **Production Use Cases:** Explore real-world applications of LLMs for data extraction, such as customer service email analysis.\n",
    "\n",
    "Here are the links used in the video:\n",
    "\n",
    "- [Jupyter Notebook](./TDS_LLM_extraction.ipynb)\n",
    "- [JSON Schema](https://json-schema.org/)\n",
    "- [Function calling](https://platform.openai.com/docs/guides/function-calling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM Topic modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll learn to use text embeddings to find text similarity and use that to create topics automatically from text, covering:\n",
    "\n",
    "- **Embeddings:** How large language models convert text into numerical representations.\n",
    "- **Similarity Measurement:** Understanding how similar embeddings indicate similar meanings.\n",
    "- **Embedding Visualization:** Using tools like Tensorflow Projector to visualize embedding spaces.\n",
    "- **Embedding Applications:** Using embeddings for tasks like classification and clustering.\n",
    "- **OpenAI Embeddings:** Using OpenAI's API to generate embeddings for text.\n",
    "- **Model Comparison:** Exploring different embedding models and their strengths and weaknesses.\n",
    "- **Cosine Similarity:** Calculating cosine similarity between embeddings for more reliable similarity measures.\n",
    "- **Embedding Cost:** Understanding the cost of generating embeddings using OpenAI's API.\n",
    "- **Embedding Range:** Understanding the range of values in embeddings and their significance.\n",
    "\n",
    "Here are the links used in the video:\n",
    "\n",
    "- [Jupyter Notebook](./TDS_Topic_Modeling.ipynb)\n",
    "- [Tensorflow projector](https://projector.tensorflow.org/)\n",
    "- [Embeddings guide](https://platform.openai.com/docs/guides/embeddings)\n",
    "- [Embeddings reference](https://platform.openai.com/docs/api-reference/embeddings)\n",
    "- [Clustering on scikit-learn](https://scikit-learn.org/stable/modules/clustering.html)\n",
    "- [Massive text embedding leaderboard (MTEB)](https://huggingface.co/spaces/mteb/leaderboard)\n",
    "- [gte-large-en-v1.5 embedding model](https://huggingface.co/Alibaba-NLP/gte-large-en-v1.5)\n",
    "- [Embeddings similarity threshold](https://www.s-anand.net/blog/embeddings-similarity-threshold/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval Augmented Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The video is not available yet. Please review the notebook, which is self-explanatory.\n",
    "\n",
    "You will learn to implement Retrieval Augmented Generation (RAG) to enhance language models' responses by incorporating relevant context, covering:\n",
    "\n",
    "- **LLM Context Limitations:** Understanding the constraints of context windows in large language models.\n",
    "- **Retrieval Augmented Generation:** The technique of retrieving and using relevant documents to enhance model responses.\n",
    "- **Embeddings:** How to convert text into numerical representations that are used for similarity calculations.\n",
    "- **Similarity Search:** Finding the most relevant documents by calculating cosine similarity between embeddings.\n",
    "- **OpenAI API Integration:** Using the OpenAI API to generate responses based on the most relevant documents.\n",
    "- **Tourist Recommendation Bot:** Building a bot that recommends tourist attractions based on user interests using embeddings.\n",
    "- **Next Steps for Implementation:** Insights into scaling the solution with a vector database, re-rankers, and improved prompts for better accuracy and efficiency.\n",
    "\n",
    "Here are the links used in the video:\n",
    "\n",
    "- [Jupyter Notebook](./TDS_Retrieval_Augmented_Generation.ipynb)\n",
    "- [gte-large-en-v1.5 embedding model](https://huggingface.co/Alibaba-NLP/gte-large-en-v1.5)\n",
    "- [Awesome vector database](https://github.com/mileszim/awesome-vector-database)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
